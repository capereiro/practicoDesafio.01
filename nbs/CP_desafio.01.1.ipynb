{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grupo 03 - Desafío 01\n",
    "## Estrategia de construcción\n",
    ">**OBJETIVO:** Crear un df de post-producción que luego se transformará en producción para realizar análisis del dataset.\n",
    "> * Se trabajará depurando cada columna del dataset con la finalidad de reconstruir datos perdidos y/o crear nuevas columnas que serán utilizadas a posteriori en la fase de análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import g3utils as g3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re as re\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga e inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de dataset inicial\n",
    "\n",
    "df = pd.DataFrame(pd.read_csv(\"../data/properatti_minusculas.csv\", encoding='UTF-8'))\n",
    "#!head nombreArchivo.cvs --> comando de linux para ver las 5 primeras lineas. Se puede utilizar para ver como estan separados los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de cantidad de filas a cargar en caso de realizar una prueba acotada\n",
    "\n",
    "ca_filas = 40\n",
    "#ca_filas = 121220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplado de NaN's para comenzar a estandarizar los datos ingresados en data frame de inicio\n",
    "\n",
    "df = g3.reemplaza_nan('sin datos',df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificación del formato del data frame incicial\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armado inicial de data frames operativos\n",
    "Este bloque se reserva para realizar la precarga inicial de distintos data frames que se utilizarán a lo largo del notebook.\n",
    "* pospo -- df de posproducción\n",
    "* df_recup -- df para persistir los elementos recuperados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dadtaframe de posproducción. Tras depurar todas las regex, este DF será la base de análisis de negocio\n",
    "# Se ejecuta una única vez y se le van incorporando las columnas depuradas.\n",
    "# Tener en cuenta que el DF pospo definitivo tiene que tener la misma cantidad de filas que el DF base len(df)\n",
    "\n",
    "pospo = g3.generar_df_posproduccion(ca_filas)\n",
    "pospo.shape\n",
    "#pospo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de df que permite registrar los valores recuperados de cada columna\n",
    "\n",
    "df_recup = pd.DataFrame()\n",
    "df_recup.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamiento de carga de columnas depuradas en data frame post-produccion 'pospo'\n",
    "> *** Modo de uso:** \n",
    ">* En este markdown se vuelcan las funciones que generan y agregan columnas depuradas dentro de pospo\n",
    ">* La codificación de desarrollo se realiza en notebook de **Desarrollo** y una vez terminado se empaqueta dentro de una función consolidadora para automatizar tareas de carga.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depuración 'ambientes' en 'description', persistencia de columna en pospro y recup\n",
    "\n",
    "def recuperar_ambientes(pospo, recup):\n",
    "    pattern = r'(\\d*\\w*)\\s*amb'  \n",
    "    \n",
    "    df1 = g3.busca_claves(pattern,'description',df.head(ca_filas))\n",
    "    dic = {'mono': 1, 'un':1, 'uno':1, 'dos':2, 'tres':3, 'cuatro':4, 'cinco':5 ,'seis':6 ,'siete':7}\n",
    "    \n",
    "    df_temp = g3.limpiar_columna_x_clave(dic, df1)\n",
    "    recuperados = df_temp[pd.notnull(df_temp[0])].count() # selecciona unicamente los recuperados del regex\n",
    "    recup = g3.registrar_recupero(int(recuperados),'r_ambientes', recup)\n",
    "    pospo = g3.agregar_columna('r_ambiente', pospo, df_temp)\n",
    "    return pospo, recup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pospo, df_recup = recuperar_ambientes(pospo, df_recup)\n",
    "print('pospo.size ==> ' + str(pospo.shape))\n",
    "print('df_recup.size ==> ' + str(df_recup.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depuración 'precio usd' en 'description', persistencia de columna en pospro y recup\n",
    "\n",
    "def recuperar_usd(pospo, recup):\n",
    "    pattern = r\"(\\d+\\.?\\,?\\d+\\.?\\,?\\d+)\\s?u[$sd]\\w?|u[$sd]\\w?\\s*(\\d+\\.?\\,?\\d+\\.?\\,?\\d+)\" # precio_usd\n",
    "    df1 = g3.busca_claves(pattern,'description',df.head(ca_filas)) # Para trabajar con un DF acotado\n",
    "    df2 = g3.obtener_df_indexado(df1, 'r_usd') # Genera DF acotado con los valores recuperados unicamente\n",
    "\n",
    "    recup = g3.registrar_recupero(len(df2),'r_usd', recup)\n",
    "\n",
    "    pospo = pd.merge(pospo, df2, on='indice', how='left')\n",
    "    return pospo, recup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pospo, df_recup = recuperar_usd(pospo, df_recup)\n",
    "print('pospo.size ==> ' + str(pospo.shape))\n",
    "print('df_recup.size ==> ' + str(df_recup.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depuración 'metros2' en 'description' y 'title', persistencia de columna en pospro y recup\n",
    "\n",
    "def recuperar_metros(pospo, recup):\n",
    "    pattern = r\"(\\d*)\\,?\\d*\\s?(?:m²|mts\\s?2|metros\\s?2|mts²|m2|metros\\s?cuadrado|mts\\s?cuadrado)\" # superficie\n",
    "    df1 = g3.busca_claves(pattern,'description',df.head(ca_filas)) # Para trabajar con un DF acotado\n",
    "    df2 = g3.obtener_df_indexado_simple(df1, 'r_metros2') # Genera DF acotado con los valores recuperados unicamente\n",
    "    \n",
    "    df3 = g3.busca_claves(pattern,'title',df.head(ca_filas))\n",
    "    df4 = g3.obtener_df_indexado_simple(df3, 'r_metros2')\n",
    "    \n",
    "    df5 = pd.concat([df2,df4]).sort_values('indice')\n",
    "    \n",
    "    recup = g3.registrar_recupero(len(df5),'r_metros2', recup)\n",
    "    \n",
    "    pospo = pd.merge(pospo, df5,on='indice', how='left').drop_duplicates(['indice'],keep='last')\n",
    "    return pospo, recup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pospo, df_recup = recuperar_metros(pospo, df_recup)\n",
    "print('pospo.size ==> ' + str(pospo.shape))\n",
    "print('df_recup.size ==> ' + str(df_recup.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depuración 'frente' en 'description' y 'title', persistencia de columna en pospro y recup\n",
    "\n",
    "def recuperar_frente(pospo, recup):\n",
    "    pattern = r\"(frente)\"\n",
    "    df1 = g3.busca_claves(pattern,'description',df.head(ca_filas)) # Para trabajar con un DF acotado\n",
    "    df2 = g3.obtener_df_indexado_simple(df1, 'r_frente')\n",
    "    \n",
    "    df3 = g3.busca_claves(pattern,'title',df.head(ca_filas))\n",
    "    df4 = g3.obtener_df_indexado_simple(df3, 'r_frente')\n",
    "    \n",
    "    df5 = pd.concat([df2,df4]).sort_values('indice')\n",
    "    \n",
    "    recup = g3.registrar_recupero(len(df5),'r_frente', recup)\n",
    "    \n",
    "    pospo = pd.merge(pospo, df5,on='indice', how='left').drop_duplicates(['indice'],keep='last')\n",
    "    return pospo, recup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pospo, df_recup = recuperar_frente(pospo, df_recup)\n",
    "print('pospo.size ==> ' + str(pospo.shape))\n",
    "print('df_recup.size ==> ' + str(df_recup.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depuración 'contrafrente' en 'description' y 'title', persistencia de columna en pospro y recup\n",
    "\n",
    "def recuperar_contrafrente(pospo, recup):\n",
    "    pattern = r\"(contrafrente)\"\n",
    "    df1 = g3.busca_claves(pattern,'description',df.head(ca_filas))\n",
    "    df2 = g3.obtener_df_indexado_simple(df1, 'r_contrafrente')\n",
    "    \n",
    "    df3 = g3.busca_claves(pattern,'title',df.head(ca_filas))\n",
    "    df4 = g3.obtener_df_indexado_simple(df3, 'r_contrafrente')\n",
    "    \n",
    "    df5 = pd.concat([df2,df4]).sort_values('indice')\n",
    "    \n",
    "    recup = g3.registrar_recupero(len(df5),'r_contrafrente', recup)\n",
    "    \n",
    "    pospo = pd.merge(pospo, df5,on='indice', how='left').drop_duplicates(['indice'],keep='last')\n",
    "    return pospo, recup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pospo, df_recup = recuperar_contrafrente(pospo, df_recup)\n",
    "print('pospo.size ==> ' + str(pospo.shape))\n",
    "print('df_recup.size ==> ' + str(df_recup.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depuración 'expensas' en 'description' y 'title', persistencia de columna en pospro y recup\n",
    "\n",
    "def recuperar_expensas(pospo, recup):\n",
    "    pattern = r\"(expensas)\"\n",
    "    df1 = g3.busca_claves(pattern,'description',df.head(ca_filas)) # Para trabajar con un DF acotado\n",
    "    df2 = g3.obtener_df_indexado_simple(df1, 'r_expensas')\n",
    "    \n",
    "    df3 = g3.busca_claves(pattern,'title',df.head(ca_filas))\n",
    "    df4 = g3.obtener_df_indexado_simple(df3, 'r_expensas')\n",
    "    \n",
    "    df5 = pd.concat([df2,df4]).sort_values('indice')\n",
    "        \n",
    "    recup = g3.registrar_recupero(len(df5),'r_expensas', recup)\n",
    "    \n",
    "    pospo = pd.merge(pospo, df5,on='indice', how='left').drop_duplicates(['indice'],keep='last')\n",
    "    return pospo, recup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pospo, df_recup = recuperar_expensas(pospo, df_recup)\n",
    "print('pospo.size ==> ' + str(pospo.shape))\n",
    "print('df_recup.size ==> ' + str(df_recup.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recuperar_garage(pospo, recup):\n",
    "    pattern = r\"(garage)|(cochera)\" # garage\n",
    "    df1 = g3.busca_claves(pattern,'description',df.head(ca_filas)) # Para trabajar con un DF acotado\n",
    "    df2 = g3.obtener_df_indexado_booleano(df1, 'r_garage') # Genera DF acotado con los valores recuperados unicamente\n",
    "    \n",
    "    df3 = g3.busca_claves(pattern,'title',df.head(ca_filas))\n",
    "    df4 = g3.obtener_df_indexado_booleano(df3, 'r_garage')\n",
    "    \n",
    "    df5 = pd.concat([df2,df4]).sort_values('indice')\n",
    "    \n",
    "    recup = g3.registrar_recupero(len(df5),'r_garage', recup)\n",
    "    \n",
    "    pospo = pd.merge(pospo, df5,on='indice', how='left').drop_duplicates(['indice'],keep='last')\n",
    "    return pospo, recup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pospo, df_recup = recuperar_garage(pospo, df_recup)\n",
    "print('pospo.size ==> ' + str(pospo.shape))\n",
    "print('df_recup.size ==> ' + str(df_recup.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recuperar_amenities(pospo, recup):\n",
    "    pattern = r\"(pileta)|(piscina)|(SUM)|(laundry)|(lavadero)|(terraza)|(solarium)|(baulera)|(sauna)|(gimnasio)|(salon de usos multiples)|(cochera)|(garage)|(gim)|(gym)\" # garage\n",
    "    df1 = g3.busca_claves(pattern,'description',df.head(ca_filas)) # Para trabajar con un DF acotado\n",
    "    df2 = g3.obtener_df_indexado_booleano(df1, 'r_amenities') # Genera DF acotado con los valores recuperados unicamente\n",
    "    \n",
    "    df3 = g3.busca_claves(pattern,'title',df.head(ca_filas))\n",
    "    df4 = g3.obtener_df_indexado_booleano(df3, 'r_amenities')\n",
    "    \n",
    "    df5 = pd.concat([df2,df4]).sort_values('indice')\n",
    "    \n",
    "    recup = g3.registrar_recupero(len(df5),'r_amenities', recup)\n",
    "    \n",
    "    pospo = pd.merge(pospo, df5,on='indice', how='left').drop_duplicates(['indice'],keep='last')\n",
    "    return pospo, recup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pospo, df_recup = recuperar_amenities(pospo, df_recup)\n",
    "print('pospo.size ==> ' + str(pospo.shape))\n",
    "print('df_recup.size ==> ' + str(df_recup.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_recup.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorporación de características originales\n",
    "* Dichas características se extraen del data frame 'df' y se persisten en 'pospo'.\n",
    "* Las características seleccionadas fueron analizadas previamente y solo se persistirán las necesarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
