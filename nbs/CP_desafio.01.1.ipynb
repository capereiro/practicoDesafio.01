{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grupo 03 - Desafío 01\n",
    "## Estrategia de construcción\n",
    ">**OBJETIVO:** Crear un df de post-producción que luego se transformará en producción para realizar análisis del dataset.\n",
    "> * Se trabajará depurando cada columna del dataset con la finalidad de reconstruir datos perdidos y/o crear nuevas columnas que serán utilizadas a posteriori en la fase de análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install unidecode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import g3utils as g3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re as re\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga e inicialización de df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del dataset en un df\n",
    "\n",
    "df = pd.DataFrame(pd.read_csv(\"../data/properatti_minusculas.csv\", encoding='UTF-8'))\n",
    "#!head nombreArchivo.cvs --> comando de linux para ver las 5 primeras lineas. Se puede utilizar para ver como estan separados los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para ver el contenido total de las columnas\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplado de NaN's\n",
    "df = g3.reemplaza_nan('sin datos',df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificación del reemplazo\n",
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armado inicial de df post-produccion\n",
    "* Este bloque se reserva para realizar la precarga inicial dentro de un df de post-producción que finalmente se transformará en dataset de producción.\n",
    "* Comenzar incluyendo aquellas columnas útiles dentro del df post-produccion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruebas de campos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Para verificar el contenido de alguna fila al azar\n",
    "df.sample(1)['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para verificar algún problema en alguna fila en particular\n",
    "df.iloc[293]['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comentar lo que no se deba ejecutar\n",
    "# Listado de todos los paterns configurados\n",
    "# regex = re.compile(pattern, flags = re.IGNORECASE) # Se ejecuta dentro de funciones específicas\n",
    "\n",
    "#pattern = r'(\\d+)\\s[m]2' # Patron para buscar metros cuadrados (m2)\n",
    "#pattern = r'(\\d*\\w*)\\s*amb'  # Patron para buscar metros ambientes\n",
    "#pattern = r'(\\d*)\\s?\\b[aA]mbientes\\w*'\n",
    "#pattern = r'(\\d*\\w*)\\s*usd'\n",
    "#pattern = r'(\\d*\\w*)\\s*habitacion|(\\d*\\w*)\\s?cuarto|(\\d*\\w*)\\s?dorm|(\\d*\\w*)\\s?pieza'\n",
    "#pattern = r\"(pileta)|(piscina)|(SUM)|(laundry)|(lavadero)|(terraza)|(solarium)|(baulera)|(sauna)|(gimnasio)|(salon de usos multiples)|(cochera)|(garage)|(gim)|(gym)\" # amenities\n",
    "#pattern = r\"(casa)|(departamento)|(triplex)|(duplex)|(frente)|(contrafrente)|(PH)|(chalet)\" # casa\n",
    "#pattern = r\"(\\d*)\\,?\\d*\\s?(?:m²|mts\\s?2|metros\\s?2|mts²|m2|metros\\s?cuadrado|mts\\s?cuadrado)\" # superficie\n",
    "pattern = r\"(\\d+\\.?\\,?\\d+\\.?\\,?\\d+)\\s?u[$sd]\\w?|u[$sd]\\w?\\s*(\\d+\\.?\\,?\\d+\\.?\\,?\\d+)\" # precio_usd\n",
    "#pattern = r\"(\\d+\\.?\\,?\\d+\\.?\\,?\\d+)\\s?\\$|\\$\\s*(\\d+\\.?\\,?\\d+\\.?\\,?\\d+)\" # precio\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_2 = pd.to_numeric(serie_1, errors='coerse', downcast='float')\n",
    "pd.Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_numeric(12.342, errors='coerse', downcast='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpieza(df):\n",
    "    laind = []\n",
    "    l_col = []\n",
    "    for i in range(len(df.index)):\n",
    "        if df.iloc[i] != None:\n",
    "            l_ind.append(i)\n",
    "            l_col.append(df.iloc[i][1])\n",
    "    lista = pd.DataFrame(l_ind, columns={'indice'})\n",
    "    lista['usd'] = pd.DataFrame(l_col)\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=limpieza(df1)\n",
    "l1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecuta función de busqueda de claves en base a los Patterns previamente configurados\n",
    "\n",
    "df1 = g3.busca_claves(pattern,'description',df.head(50000)) # Para trabajar con un DF acotado\n",
    "#df1 = g3.busca_claves(pattern,'description',df) # Para trabajar con el DF completo\n",
    "#df1.iloc[1][1]\n",
    "#df1 = g3.reemplaza_nan('sin datos',df1)\n",
    "df1\n",
    "#df1.iloc[2]\n",
    "#len(df1.iloc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamiento de limpieza y carga de columna depurada en df post-produccion\n",
    "> *** Modo de uso:** \n",
    ">* Una vez determinado la finalización de la depuración de columna, confeccionar un grupo de código con todas las lineas de carga.\n",
    "> * Cada grupo de código se utiliza para realizar el proceso de limpieza x clave. Si se cambia de clave, armar otro grupo de código.\n",
    ">  1. DataFrame posproduccion = `dfpos`.\n",
    ">  2. Determinar patron regex  `pattern`.\n",
    ">  3. Ejecutar busqueda de claves en una determinada columna `g3.busca_claves()`.\n",
    ">  3. Determinar diccionario de claves y sus significados `dic`.\n",
    ">  4. Ejecutar limpieza basada en diccionario de claves `g3.limpiar_columna_x_clave()`.\n",
    ">  5. Cargar columna depurada dentro del df post-produccion `g3.agregar_columna()`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depuración 'ambientes'\n",
    "\n",
    "pattern = r'(\\d*\\w*)\\s*amb'  # Patron para buscar metros ambientes\n",
    "df1 = g3.busca_claves(pattern,'description',df.head(30))\n",
    "dic = {'mono': 1, 'un':1, 'uno':1, 'dos':2, 'tres':3, 'cuatro':4, 'cinco':5 ,'seis':6 ,'siete':7}\n",
    "df_temp = g3.limpiar_columna_x_clave(dic, df1)\n",
    "#dfpos = g3.agregar_columna('ambiente', dfpos, df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depuración 'ambientes'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [FIN] Procesamiento de limpieza y carga de columna depurada en df post-produccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamiento de armado intermedio de df de post-produccion\n",
    "> * Modo de uso temporal hasta terminar de depurar todas las claves necesarias\n",
    "> * Cada grupo de código se utiliza para realizar consolidado de filas dentro del DF que luego será el definitivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armado de dataset definitivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregado de columna limpia a DF definitivo\n",
    "dfx = g3.agregar_columna('ambiente', dfx, df_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------\n",
    "# SIN USO\n",
    "# ------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp_df = df[\"cases\"].str.extract(\"([a-z])([0-9]+)([0-9]{2})\",expand=True) \n",
    "tmp_df = df[\"description\"].str.extract(\"((\\d*)\\s?\\b[aA]mb\\w*)\",expand=True) \n",
    "tmp_df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST: Regex de prueba. Alimenta un DF con el resultado\n",
    "# CONDICION: No lee NaN's\n",
    "# NOTA: Me di cuenta que REGEX analiza todo el str y en muchos casos detecta la KEY en varias partes del \n",
    "#   str, ergo, al capturar el siguiente dato, lo incluye dentro de una lista y eso lo representa en otra columna\n",
    "#   Entonces ponerle nombre a una única columna no tendría sentido. Si verificamos con .head(10) no vamos\n",
    "#   a tener problemas porque justo las 10 primeras filas no tienen mas de una KEY en el str a analizar...\n",
    "\n",
    "#m = pd.DataFrame([regex.findall(n) for n in df_a1['description'].head(10)], columns=[\"ambientes\"] )\n",
    "m = pd.DataFrame([regex.findall(n) for n in df_a1['description'].head(50)])\n",
    "#m = pd.DataFrame([regex.findall(n) for n in df_a1['description']])\n",
    "display(len(m))\n",
    "#m\n",
    "m[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coloco nombre en la columna para luego hacer merge\n",
    "\n",
    "df1.rename(columns={0:'ambientes'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reemplazo de NaN's\n",
    "Esto se realiza porque la función de búsqueda explotaba "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a1=df.replace(np.nan,'sin-dato')\n",
    "#df_a1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reemplaza_nan(df, clave):\n",
    "    return df.replace(np.nan,clave)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca claves segun pattern en columna dentro de dataFrame \n",
    "# Entrada: pattern, columna, df\n",
    "# Salida: DataFrame\n",
    "\n",
    "def busca_claves(pattern, columna, df_aux):\n",
    "    regex = re.compile(pattern, flags = re.IGNORECASE)\n",
    "    m = pd.DataFrame([regex.findall(n) for n in df_aux[columna].head(10000)])\n",
    "    return m[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def existe_clave(key, columna, df_aux):    \n",
    "    m = []\n",
    "    for frase in df_aux[columna]:\n",
    "        if key in frase:\n",
    "            m.append(True)\n",
    "        else:\n",
    "            m.append(False)\n",
    "    return sum(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No se está utilizando mas desde que el dataset se encuentra en minúsculas y sin acentos\n",
    "def quitar_caracteres(column):\n",
    "    for i in range(len(column)):\n",
    "        if type(column[i]) == str:\n",
    "            column[i] = str.lower(unidecode.unidecode(column[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambia los literales numericos x floats. En caso de no detectar la clave en un diccionario, reemplaza por NaN.\n",
    "# El reemplazo x NaN se hace para poder realizar operaciones.\n",
    "# Mejoras: debiera recibir diccionario y lista_prop como parametros para dejar una función polimorfica. \n",
    "# Entrada: DataFrame\n",
    "# Salida: DataFrame\n",
    "\n",
    "def cambiar_x_nros(df):\n",
    "    dic = {'mono': 1, 'un':1, 'uno':1, 'dos':2, 'tres':3, 'cuatro':4, 'cinco':5 ,'seis':6 ,'siete':7}\n",
    "    lista_prop = ['mono','un','uno','dos','tres','cuatro','cinco','seis','siete']\n",
    "    serie_1 = pd.Series([x if x not in lista_prop else dic.get(x) for x in df])\n",
    "    serie_2 = pd.to_numeric(serie_1, errors='coerse', downcast='float') # coerse: pasa a NaN los no-numericos\n",
    "    return pd.DataFrame(serie_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quitar_caracteres(df[\"place_name\"])\n",
    "quitar_caracteres(df[\"place_with_parent_names\"])\n",
    "quitar_caracteres(df[\"country_name\"])\n",
    "quitar_caracteres(df[\"state_name\"])\n",
    "quitar_caracteres(df[\"description\"])\n",
    "quitar_caracteres(df[\"title\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
