{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grupo 03 - Desafío 01\n",
    "## Estrategia de construcción - Desarrollo\n",
    ">**OBJETIVO:** Crear un df de post-producción que luego se transformará en producción para realizar análisis del dataset.\n",
    "> * Se trabajará depurando cada columna del dataset con la finalidad de reconstruir datos perdidos y/o crear nuevas columnas que serán utilizadas a posteriori en la fase de análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install unidecode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import g3utils as g3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re as re\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga e inicialización de df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de filas a cargar en las pruebas\n",
    "ca_filas = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del dataset en un df\n",
    "\n",
    "df = pd.DataFrame(pd.read_csv(\"../data/properatti_minusculas.csv\", encoding='UTF-8'))\n",
    "#!head nombreArchivo.cvs --> comando de linux para ver las 5 primeras lineas. Se puede utilizar para ver como estan separados los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para ver el contenido total de las columnas\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplado de NaN's\n",
    "df = g3.reemplaza_nan('sin datos',df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121220, 27)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificación del reemplazo\n",
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrega de caracteristicas de data frame original a pospo\n",
    "* Este bloque se reserva para realizar la precarga inicial dentro de un df de post-producción que finalmente se transformará en dataset de producción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['surface_total_in_m2'].isnull())&(df['surface_covered_in_m2'].isnull())].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pospo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_carac = ['property_type','place_name','state_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pospo.merge(df[lista_carac].head(ca_filas), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['lat-lon'].notnull())&(df.geonames_id.isnull())].shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Armado inicial de df's\n",
    "* Este bloque se reserva para realizar la precarga inicial dentro de un df de post-producción que finalmente se transformará en dataset de producción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dadtaframe de posproducción. Tras depurar todas las regex, este DF será la base de análisis de negocio\n",
    "# Se ejecuta una única vez y se le van incorporando las columnas depuradas.\n",
    "# Tener en cuenta que el DF pospo definitivo tiene que tener la misma cantidad de filas que el DF base len(df)\n",
    "\n",
    "pospo = g3.generar_df_posproduccion(ca_filas)\n",
    "pospo.shape\n",
    "#pospo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición de df que permite registrar los valores recuperados de cada columna\n",
    "\n",
    "df_recup = pd.DataFrame()\n",
    "df_recup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de limpieza y carga de columnas depuradas en df post-produccion 'pospo'\n",
    "> *** Modo de uso:** \n",
    ">* En este markdown se vuelcan las funciones que generan y agregan columnas depuradas dentro de pospo\n",
    ">* La codificación de desarrollo se realiza mas abajo dentro del título **Desarrollo** y una vez terminado se empaqueta dentro de una función consolidadora.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recuperar_usd(pospo, recup):\n",
    "    pattern = r\"(\\d+\\.?\\,?\\d+\\.?\\,?\\d+)\\s?u[$sd]\\w?|u[$sd]\\w?\\s*(\\d+\\.?\\,?\\d+\\.?\\,?\\d+)\" # precio_usd\n",
    "    df1 = g3.busca_claves(pattern,'description',df.head(ca_filas)) # Para trabajar con un DF acotado\n",
    "    df2 = g3.obtener_df_indexado(df1, 'r_usd') # Genera DF acotado con los valores recuperados unicamente\n",
    "\n",
    "    recup = g3.registrar_recupero(len(df2),'r_usd', recup)\n",
    "\n",
    "    pospo = pd.merge(pospo, df2, on='indice', how='left')\n",
    "    return pospo, recup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recuperar_metros(pospo, recup):\n",
    "    pattern = r\"(\\d*)\\,?\\d*\\s?(?:m²|mts\\s?2|metros\\s?2|mts²|m2|metros\\s?cuadrado|mts\\s?cuadrado)\" # superficie\n",
    "    df1 = g3.busca_claves(pattern,'description',df.head(ca_filas)) # Para trabajar con un DF acotado\n",
    "    df2 = g3.obtener_df_indexado_simple(df1, 'r_metros2') # Genera DF acotado con los valores recuperados unicamente\n",
    "    \n",
    "    df3 = g3.busca_claves(pattern,'title',df.head(ca_filas))\n",
    "    df4 = g3.obtener_df_indexado_simple(df3, 'r_metros2')\n",
    "    \n",
    "    df5 = pd.concat([df2,df4]).sort_values('indice')\n",
    "    \n",
    "    recup = g3.registrar_recupero(len(df5),'r_metros2', recup)\n",
    "    \n",
    "    pospo = pd.merge(pospo, df5,on='indice', how='left').drop_duplicates(['indice'],keep='last')\n",
    "    return pospo, recup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recuperar_garage(pospo, recup):\n",
    "    pattern = r\"(garage)|(cochera)\" # garage\n",
    "    df1 = g3.busca_claves(pattern,'description',df.head(ca_filas)) # Para trabajar con un DF acotado\n",
    "    df2 = g3.obtener_df_indexado_booleano(df1, 'r_garage') # Genera DF acotado con los valores recuperados unicamente\n",
    "    \n",
    "    df3 = g3.busca_claves(pattern,'title',df.head(ca_filas))\n",
    "    df4 = g3.obtener_df_indexado_booleano(df3, 'r_garage')\n",
    "    \n",
    "    df5 = pd.concat([df2,df4]).sort_values('indice')\n",
    "    \n",
    "    recup = g3.registrar_recupero(len(df5),'r_garage', recup)\n",
    "    \n",
    "    pospo = pd.merge(pospo, df5,on='indice', how='left').drop_duplicates(['indice'],keep='last')\n",
    "    return pospo, recup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pospo.size ==> (40, 2)\n",
      "df_recup.size ==> (1, 1)\n"
     ]
    }
   ],
   "source": [
    "pospo, df_recup = recuperar_garage(pospo, df_recup)\n",
    "print('pospo.size ==> ' + str(pospo.shape))\n",
    "print('df_recup.size ==> ' + str(df_recup.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recuperar_amenities(pospo, recup):\n",
    "    pattern = r\"(pileta)|(piscina)|(SUM)|(laundry)|(lavadero)|(terraza)|(solarium)|(baulera)|(sauna)|(gimnasio)|(salon de usos multiples)|(cochera)|(garage)|(gim)|(gym)\" # garage\n",
    "    df1 = g3.busca_claves(pattern,'description',df.head(ca_filas)) # Para trabajar con un DF acotado\n",
    "    df2 = g3.obtener_df_indexado_booleano(df1, 'r_amenities') # Genera DF acotado con los valores recuperados unicamente\n",
    "    \n",
    "    df3 = g3.busca_claves(pattern,'title',df.head(ca_filas))\n",
    "    df4 = g3.obtener_df_indexado_booleano(df3, 'r_amenities')\n",
    "    \n",
    "    df5 = pd.concat([df2,df4]).sort_values('indice')\n",
    "    \n",
    "    recup = g3.registrar_recupero(len(df5),'r_amenities', recup)\n",
    "    \n",
    "    pospo = pd.merge(pospo, df5,on='indice', how='left').drop_duplicates(['indice'],keep='last')\n",
    "    return pospo, recup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pospo.size ==> (40, 3)\n",
      "df_recup.size ==> (1, 2)\n"
     ]
    }
   ],
   "source": [
    "pospo, df_recup = recuperar_amenities(pospo, df_recup)\n",
    "print('pospo.size ==> ' + str(pospo.shape))\n",
    "print('df_recup.size ==> ' + str(df_recup.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indice</th>\n",
       "      <th>r_garage</th>\n",
       "      <th>r_amenities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    indice  r_garage  r_amenities\n",
       "0        0       NaN          1.0\n",
       "1        1       1.0          1.0\n",
       "2        2       NaN          1.0\n",
       "3        3       NaN          NaN\n",
       "4        4       NaN          NaN\n",
       "5        5       NaN          1.0\n",
       "6        6       NaN          1.0\n",
       "7        7       NaN          1.0\n",
       "8        8       NaN          1.0\n",
       "9        9       NaN          1.0\n",
       "10      10       1.0          1.0\n",
       "11      11       NaN          1.0\n",
       "12      12       NaN          1.0\n",
       "13      13       NaN          1.0\n",
       "14      14       NaN          1.0\n",
       "15      15       1.0          1.0\n",
       "16      16       NaN          NaN\n",
       "17      17       1.0          1.0\n",
       "18      18       NaN          1.0\n",
       "20      19       NaN          1.0\n",
       "21      20       NaN          NaN\n",
       "22      21       NaN          NaN\n",
       "23      22       NaN          1.0\n",
       "24      23       1.0          1.0\n",
       "25      24       1.0          1.0\n",
       "26      25       1.0          1.0\n",
       "27      26       NaN          1.0\n",
       "28      27       NaN          1.0\n",
       "29      28       1.0          1.0\n",
       "30      29       NaN          NaN\n",
       "31      30       1.0          1.0\n",
       "32      31       NaN          NaN\n",
       "33      32       NaN          NaN\n",
       "34      33       1.0          1.0\n",
       "35      34       1.0          1.0\n",
       "36      35       NaN          NaN\n",
       "37      36       1.0          1.0\n",
       "38      37       NaN          NaN\n",
       "40      38       1.0          1.0\n",
       "41      39       1.0          1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pospo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"(pileta)|(piscina)|(SUM)|(laundry)|(lavadero)|(terraza)|(solarium)|(baulera)|(sauna)|(gimnasio)|(salon de usos multiples)|(cochera)|(garage)|(gim)|(gym)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    pattern = r\"(pileta)|(piscina)|(SUM)|(laundry)|(lavadero)|(terraza)|(solarium)|(baulera)|(sauna)|(gimnasio)|(salon de usos multiples)|(cochera)|(garage)|(gim)|(gym)\"\n",
    "    df1 = g3.busca_claves(pattern,'description',df.head(ca_filas)) # Para trabajar con un DF acotado\n",
    "    df2 = g3.obtener_df_indexado_booleano(df1, 'r_amenities') # Genera DF acotado con los valores recuperados unicamente\n",
    "    \n",
    "    df3 = g3.busca_claves(pattern,'title',df.head(ca_filas))\n",
    "    df4 = obtener_df_indexado_booleano(df3, 'r_amenities')\n",
    "    \n",
    "    df5 = pd.concat([df2,df4]).sort_values('indice')\n",
    "    \n",
    "    recup = g3.registrar_recupero(len(df5),'r_amenities', recup)\n",
    "    \n",
    "    pospo = pd.merge(pospo, df5,on='indice', how='left').drop_duplicates(['indice'],keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"(pileta)|(piscina)|(SUM)|(laundry)|(terraza)|(solarium)|(baulera)|(sauna)|(gimnasio)|(salon de usos multiples)|(gim)|(gym)\"\n",
    "df1 = g3.busca_claves(pattern,'description',df.head(ca_filas)) # Para trabajar con un DF acotado\n",
    "df2 = obtener_df_indexado_booleano(df1, 'r_amenities') # Genera DF acotado con los valores recuperados unicamente\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    df3 = g3.busca_claves(pattern,'title',df.head(ca_filas))\n",
    "    df4 = obtener_df_indexado_booleano(df3, 'r_amenities')\n",
    "    \n",
    "    df5 = pd.concat([df2,df4]).sort_values('indice')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df5, len(df5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df2, len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pospo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_df_indexado_booleano(df, ncol, clave=None):\n",
    "    \"\"\"\n",
    "    Busca en datos no-None y confecciona un data frame indexado incluyendo nombres a las columnas.\n",
    "    Adicionalmente puede buscar por una clave distinta de None que puede ingresarse como parámetro.\n",
    "    A diferencia de 'obtener_df_indexado', 'obtener_df_indexado_simple' operara sobre estructuras de datos simples como un str o int\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    arg : df, ncol, clave [Opcional, default = None]\n",
    "    \n",
    "    df -- data frame\n",
    "    ncol -- nombre de columna indexada\n",
    "    clave -- parámetro opcional. Clave distinta de None. Por defecto es None\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    df_ret : data frame de dos dimensiones (indice & ncol).\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    l_ind = []\n",
    "    l_col = []\n",
    "    for i in range(len(df.index)):\n",
    "        if df.iloc[i] != clave:\n",
    "            l_ind.append(i)\n",
    "            l_col.append(1.00)\n",
    "    df_ret = pd.DataFrame(l_ind, columns={'indice'})\n",
    "    df_ret[ncol] = pd.DataFrame(l_col)\n",
    "    return df_ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'contrafrente'\n",
    "desc = g3.existe_clave(key, 'description', df)\n",
    "tit = g3.existe_clave(key, 'title', df)\n",
    "print('Datos recuperados: \"description\" ==> ',desc, '\"title\" ==> ',tit, '\"Total\" ==> ',desc+tit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pospo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g3.crear_csv('test.csv',df_recup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desarrollo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_claves(pattern, columna, df_aux):\n",
    "    regex = re.compile(pattern, flags = re.IGNORECASE)\n",
    "    m = pd.DataFrame([regex.findall(n) for n in df_aux[columna]])\n",
    "    return m[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def registrar_recupero(valor, colu, df_recup):\n",
    "    \n",
    "    if df_recup.size == 0:     \n",
    "        df_recup = pd.DataFrame([valor], columns=[colu])\n",
    "        print('primer dato en df')\n",
    "    elif colu not in df_recup.columns:\n",
    "        df_recup[colu] = [valor+1]\n",
    "        print('columna creada')\n",
    "    else:\n",
    "        df_recup[colu] = [valor+2]\n",
    "        print('columna existente')\n",
    "    return df_recup\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_csv(nombre, def_recup):\n",
    "    ruta = '../data/'+nombre\n",
    "    df_recup.to_csv(ruta, encoding='utf-8')\n",
    "    return print('[LOG] Se ha creado el archivo: ',nombre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1),len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = g3.busca_claves(pattern,'title',df.head(ca_filas))\n",
    "df4 = g3.obtener_df_indexado_simple(df3, 'r_frente')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df3),len(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.concat([df2,df4]).sort_values('indice')\n",
    "    \n",
    "pospo = pd.merge(pospo, df5,on='indice', how='left').drop_duplicates(['indice'],keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df5),len(pospo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df2, df4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comentar lo que no se deba ejecutar\n",
    "# Listado de todos los paterns configurados\n",
    "# regex = re.compile(pattern, flags = re.IGNORECASE) # Se ejecuta dentro de funciones específicas\n",
    "\n",
    "# pattern = r'(\\d+)\\s[m]2' # Patron para buscar metros cuadrados (m2)\n",
    "# pattern = r'(\\d*\\w*)\\s*amb'  # Patron para buscar ambientes OK\n",
    "# pattern = r'(\\d*)\\s?\\b[aA]mbientes\\w*'\n",
    "# pattern = r'(\\d*\\w*)\\s*usd'\n",
    "# pattern = r'(\\d*\\w*)\\s*habitacion|(\\d*\\w*)\\s?cuarto|(\\d*\\w*)\\s?dorm|(\\d*\\w*)\\s?pieza'\n",
    "# pattern = r\"(pileta)|(piscina)|(SUM)|(laundry)|(lavadero)|(terraza)|(solarium)|(baulera)|(sauna)|(gimnasio)|(salon de usos multiples)|(cochera)|(garage)|(gim)|(gym)\" # amenities\n",
    "# pattern = r\"(triplex)|(duplex)|(frente)|(contrafrente)|(PH)|(chalet)\" # casa\n",
    "# pattern = r\"(casa)|(departamento)|(triplex)|(duplex)|(frente)|(contrafrente)|(PH)|(chalet)\" # casa\n",
    "# pattern = r\"(\\d*)\\,?\\d*\\s?(?:m²|mts\\s?2|metros\\s?2|mts²|m2|metros\\s?cuadrado|mts\\s?cuadrado)\" # superficie\n",
    "# pattern = r\"(\\d+\\.?\\,?\\d+\\.?\\,?\\d+)\\s?u[$sd]\\w?|u[$sd]\\w?\\s*(\\d+\\.?\\,?\\d+\\.?\\,?\\d+)\" # precio_usd OK\n",
    "# pattern = r\"(\\d+\\.?\\,?\\d+\\.?\\,?\\d+)\\s?\\$|\\$\\s*(\\d+\\.?\\,?\\d+\\.?\\,?\\d+)\" # precio\n",
    "pattern = r\"(garage)|(cochera)\" # garage\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Depuración sobre feature **'description'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'contrafrente'\n",
    "desc = existe_clave(key, 'description', df)\n",
    "tit = existe_clave(key, 'title', df)\n",
    "print('Datos recuperados: \"description\" ==> ',desc, '\"title\" ==> ',tit)\n",
    "print('Total recuperados ==> ',desc+tit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pospo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"(frente)|(contrafrente)\" # casa\n",
    "df1 = g3.busca_claves(pattern,'description',df.head(ca_filas)) # Para trabajar con un DF acotado\n",
    "\n",
    "#df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = g3.reemplaza_nan('sin datos',df1)\n",
    "df1[0]=='sin dato'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecuta función de busqueda de claves en base a los Patterns previamente configurados\n",
    "\n",
    "df1 = g3.busca_claves(pattern,'description',df.head(ca_filas)) # Para trabajar con un DF acotado\n",
    "#df1 = g3.busca_claves(pattern,'description',df) # Para trabajar con el DF completo\n",
    "#df1 = g3.reemplaza_nan('sin datos',df1)\n",
    "df1\n",
    "#df1.iloc[2]\n",
    "#len(df1.iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = g3.obtener_df_indexado(df1, 'metros2') # Genera DF acotado con los valores recuperados unicamente\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [FIN] Procesamiento de limpieza y carga de columna depurada en df post-produccion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamiento de armado intermedio de df de post-produccion\n",
    "> * Modo de uso temporal hasta terminar de depurar todas las claves necesarias\n",
    "> * Cada grupo de código se utiliza para realizar consolidado de filas dentro del DF que luego será el definitivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armado de dataset definitivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregado de columna limpia a DF definitivo\n",
    "dfx = g3.agregar_columna('ambiente', dfx, df_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------\n",
    "# SIN USO\n",
    "# ------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp_df = df[\"cases\"].str.extract(\"([a-z])([0-9]+)([0-9]{2})\",expand=True) \n",
    "tmp_df = df[\"description\"].str.extract(\"((\\d*)\\s?\\b[aA]mb\\w*)\",expand=True) \n",
    "tmp_df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST: Regex de prueba. Alimenta un DF con el resultado\n",
    "# CONDICION: No lee NaN's\n",
    "# NOTA: Me di cuenta que REGEX analiza todo el str y en muchos casos detecta la KEY en varias partes del \n",
    "#   str, ergo, al capturar el siguiente dato, lo incluye dentro de una lista y eso lo representa en otra columna\n",
    "#   Entonces ponerle nombre a una única columna no tendría sentido. Si verificamos con .head(10) no vamos\n",
    "#   a tener problemas porque justo las 10 primeras filas no tienen mas de una KEY en el str a analizar...\n",
    "\n",
    "#m = pd.DataFrame([regex.findall(n) for n in df_a1['description'].head(10)], columns=[\"ambientes\"] )\n",
    "m = pd.DataFrame([regex.findall(n) for n in df_a1['description'].head(50)])\n",
    "#m = pd.DataFrame([regex.findall(n) for n in df_a1['description']])\n",
    "display(len(m))\n",
    "#m\n",
    "m[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruebas de campos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Para verificar el contenido de alguna fila al azar\n",
    "df.sample(1)['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para verificar algún problema en alguna fila en particular\n",
    "df.iloc[280]['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.iloc[277]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reemplazo de NaN's\n",
    "Esto se realiza porque la función de búsqueda explotaba "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a1=df.replace(np.nan,'sin-dato')\n",
    "#df_a1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reemplaza_nan(df, clave):\n",
    "    return df.replace(np.nan,clave)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca claves segun pattern en columna dentro de dataFrame \n",
    "# Entrada: pattern, columna, df\n",
    "# Salida: DataFrame\n",
    "\n",
    "def busca_claves(pattern, columna, df_aux):\n",
    "    regex = re.compile(pattern, flags = re.IGNORECASE)\n",
    "    m = pd.DataFrame([regex.findall(n) for n in df_aux[columna].head(10000)])\n",
    "    return m[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def existe_clave(key, columna, df_aux):    \n",
    "    m = []\n",
    "    for frase in df_aux[columna]:\n",
    "        if key in frase:\n",
    "            m.append(True)\n",
    "        else:\n",
    "            m.append(False)\n",
    "    return sum(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No se está utilizando mas desde que el dataset se encuentra en minúsculas y sin acentos\n",
    "def quitar_caracteres(column):\n",
    "    for i in range(len(column)):\n",
    "        if type(column[i]) == str:\n",
    "            column[i] = str.lower(unidecode.unidecode(column[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambia los literales numericos x floats. En caso de no detectar la clave en un diccionario, reemplaza por NaN.\n",
    "# El reemplazo x NaN se hace para poder realizar operaciones.\n",
    "# Mejoras: debiera recibir diccionario y lista_prop como parametros para dejar una función polimorfica. \n",
    "# Entrada: DataFrame\n",
    "# Salida: DataFrame\n",
    "\n",
    "def cambiar_x_nros(df):\n",
    "    dic = {'mono': 1, 'un':1, 'uno':1, 'dos':2, 'tres':3, 'cuatro':4, 'cinco':5 ,'seis':6 ,'siete':7}\n",
    "    lista_prop = ['mono','un','uno','dos','tres','cuatro','cinco','seis','siete']\n",
    "    serie_1 = pd.Series([x if x not in lista_prop else dic.get(x) for x in df])\n",
    "    serie_2 = pd.to_numeric(serie_1, errors='coerse', downcast='float') # coerse: pasa a NaN los no-numericos\n",
    "    return pd.DataFrame(serie_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quitar_caracteres(df[\"place_name\"])\n",
    "quitar_caracteres(df[\"place_with_parent_names\"])\n",
    "quitar_caracteres(df[\"country_name\"])\n",
    "quitar_caracteres(df[\"state_name\"])\n",
    "quitar_caracteres(df[\"description\"])\n",
    "quitar_caracteres(df[\"title\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
